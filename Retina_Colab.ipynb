{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "print(len(os.listdir('annotations')))\n",
    "print(len(os.listdir('images')))\n",
    "\n",
    "!mkdir test_images\n",
    "!mkdir test_annotations\n",
    "\n",
    "\n",
    "random.seed(1234)\n",
    "idx = random.sample(range(853), 170)\n",
    "\n",
    "for img in np.array(sorted(os.listdir('images')))[idx]:\n",
    "    shutil.move('images/'+img, 'test_images/'+img)\n",
    "\n",
    "for annot in np.array(sorted(os.listdir('annotations')))[idx]:\n",
    "    shutil.move('annotations/'+annot, 'test_annotations/'+annot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "def generate_box(obj):\n",
    "    \n",
    "    xmin = float(obj.find('xmin').text)\n",
    "    ymin = float(obj.find('ymin').text)\n",
    "    xmax = float(obj.find('xmax').text)\n",
    "    ymax = float(obj.find('ymax').text)\n",
    "    \n",
    "    return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "def generate_label(obj):\n",
    "\n",
    "    if obj.find('name').text == \"with_mask\":\n",
    "\n",
    "        return 1\n",
    "\n",
    "    elif obj.find('name').text == \"mask_weared_incorrect\":\n",
    "\n",
    "        return 2\n",
    "\n",
    "    return 0\n",
    "\n",
    "def generate_target(file): \n",
    "    with open(file) as f:\n",
    "        data = f.read()\n",
    "        soup = BeautifulSoup(data, \"html.parser\")\n",
    "        objects = soup.find_all(\"object\")\n",
    "\n",
    "        num_objs = len(objects)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for i in objects:\n",
    "            boxes.append(generate_box(i))\n",
    "            labels.append(generate_label(i))\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32) \n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64) \n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        \n",
    "        return target\n",
    "\n",
    "def plot_image_from_output(img, annotation):\n",
    "    \n",
    "    img = img.cpu().permute(1,2,0)\n",
    "    \n",
    "    rects = []\n",
    "\n",
    "    for idx in range(len(annotation[\"boxes\"])):\n",
    "        xmin, ymin, xmax, ymax = annotation[\"boxes\"][idx]\n",
    "\n",
    "        if annotation['labels'][idx] == 0 :\n",
    "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='r',facecolor='none')\n",
    "        \n",
    "        elif annotation['labels'][idx] == 1 :\n",
    "            \n",
    "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='g',facecolor='none')\n",
    "            \n",
    "        else :\n",
    "        \n",
    "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='orange',facecolor='none')\n",
    "\n",
    "        rects.append(rect)\n",
    "\n",
    "    return img, rects\n",
    "\n",
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.imgs = list(sorted(os.listdir(self.path)))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_image = self.imgs[idx]\n",
    "        file_label = self.imgs[idx][:-3] + 'xml'\n",
    "        img_path = os.path.join(self.path, file_image)\n",
    "        \n",
    "        if 'test' in self.path:\n",
    "            label_path = os.path.join(\"test_annotations/\", file_label)\n",
    "        else:\n",
    "            label_path = os.path.join(\"annotations/\", file_label)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        target = generate_target(label_path)\n",
    "        \n",
    "        to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "        if self.transform:\n",
    "            img, transform_target = self.transform(np.array(img), np.array(target['boxes']))\n",
    "            target['boxes'] = torch.as_tensor(transform_target)\n",
    "\n",
    "        # tensor로 변경\n",
    "        img = to_tensor(img)\n",
    "\n",
    "\n",
    "        return img, target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "dataset = MaskDataset('images/')\n",
    "test_dataset = MaskDataset('test_images/')\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=4, collate_fn=collate_fn)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install torch==1.7.0+cu100 torchvision==0.8.1+cu100 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import torchvision\n",
    "import torch\n",
    "torchvision.__version__\n",
    "torch.__version__\n",
    "# cuda 10.1 이어야 하는데 딥컴은 cuda 10.0후...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.models.detection' has no attribute 'retinanet_resnet50_fpn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-77acdc071f23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mretina\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretinanet_resnet50_fpn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained_backbone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torchvision.models.detection' has no attribute 'retinanet_resnet50_fpn'"
     ]
    }
   ],
   "source": [
    "retina = torchvision.models.detection.retinanet_resnet50_fpn(num_classes = 3, pretrained=False, pretrained_backbone = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_epochs = 30\n",
    "retina.to(device)\n",
    "    \n",
    "# parameters\n",
    "params = [p for p in retina.parameters() if p.requires_grad] # gradient calculation이 필요한 params만 추출\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "len_dataloader = len(data_loader)\n",
    "\n",
    "# epoch 당 약 4분 소요\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    retina.train()\n",
    "\n",
    "    i = 0    \n",
    "    epoch_loss = 0\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = retina(images, targets) \n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values()) \n",
    "\n",
    "        i += 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += losses \n",
    "    print(epoch_loss, f'time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(retina.state_dict(),f'retina_{num_epochs}.pt')\n",
    "retina.load_state_dict(torch.load(f'retina_{num_epochs}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "retina.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, img, threshold):\n",
    "    model.eval()\n",
    "    preds = model(img)\n",
    "    for id in range(len(preds)) :\n",
    "        idx_list = []\n",
    "\n",
    "        for idx, score in enumerate(preds[id]['scores']) :\n",
    "            if score > threshold : #threshold 넘는 idx 구함\n",
    "                idx_list.append(idx)\n",
    "\n",
    "        preds[id]['boxes'] = preds[id]['boxes'][idx_list]\n",
    "        preds[id]['labels'] = preds[id]['labels'][idx_list]\n",
    "        preds[id]['scores'] = preds[id]['scores'][idx_list]\n",
    "\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "labels = []\n",
    "preds_adj_all = []\n",
    "annot_all = []\n",
    "\n",
    "for im, annot in tqdm(test_data_loader, position = 0, leave = True):\n",
    "    im = list(img.to(device) for img in im)\n",
    "    #annot = [{k: v.to(device) for k, v in t.items()} for t in annot]\n",
    "\n",
    "    for t in annot:\n",
    "        labels += t['labels']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds_adj = make_prediction(retina, im, 0.5)\n",
    "        preds_adj = [{k: v.to(torch.device('cpu')) for k, v in t.items()} for t in preds_adj]\n",
    "        preds_adj_all.append(preds_adj)\n",
    "        annot_all.append(annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 8\n",
    "ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*4, nrows*4))\n",
    "\n",
    "batch_i = 0\n",
    "for im, annot in test_data_loader:\n",
    "    pos = batch_i * 4 + 1\n",
    "    for sample_i in range(len(im)) :\n",
    "        \n",
    "        img, rects = plot_image_from_output(im[sample_i], annot[sample_i])\n",
    "        axes[(pos)//2, 1-((pos)%2)].imshow(img)\n",
    "        for rect in rects:\n",
    "            axes[(pos)//2, 1-((pos)%2)].add_patch(rect)\n",
    "        \n",
    "        img, rects = plot_image_from_output(im[sample_i], preds_adj_all[batch_i][sample_i])\n",
    "        axes[(pos)//2, 1-((pos+1)%2)].imshow(img)\n",
    "        for rect in rects:\n",
    "            axes[(pos)//2, 1-((pos+1)%2)].add_patch(rect)\n",
    "\n",
    "        pos += 2\n",
    "\n",
    "    batch_i += 1\n",
    "    if batch_i == 4:\n",
    "        break\n",
    "\n",
    "# xtick, ytick 제거\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "colnames = ['True', 'Pred']\n",
    "\n",
    "for idx, ax in enumerate(axes[0]):\n",
    "    ax.set_title(colnames[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
